{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadir = '/home/madhatter106/DATA/Beaching_Project/CapeCodData/'\n",
    "magdir = os.path.join(datadir, 'Mag/')\n",
    "pkldir = os.path.join(datadir, 'PklJar/')\n",
    "dataFRD = os.path.join(magdir, 'frd')\n",
    "dataOTT = os.path.join(magdir, 'ott') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseTxtFile(fp, station='FRD'):\n",
    "    dfTemp = pd.DataFrame(columns=['%sH' % station, '%sV' % station])\n",
    "    try:\n",
    "        df = pd.read_csv(fp, skiprows=12, delim_whitespace=True,\n",
    "                         parse_dates=[[0, 1]], index_col=0 )\n",
    "    except Exception:\n",
    "        try:\n",
    "            df = pd.read_csv(fp, skiprows=24, delim_whitespace=True,\n",
    "                             parse_dates=[[0, 1]], index_col=0)\n",
    "        except Exception:\n",
    "            try:\n",
    "                df = pd.read_csv(fp, skiprows=25, delim_whitespace=True,\n",
    "                                 parse_dates=[[0, 1]], index_col=0)\n",
    "            except Exception:\n",
    "                print(\"file %s failed\" % fp, flush=True)\n",
    "                return None\n",
    "    finally:\n",
    "        df = df.resample('D').mean()\n",
    "        if '%sX' % station in df.columns:\n",
    "            dfTemp['%sH' % station] = np.sqrt(np.power(df['%sX' % station],2) +\n",
    "                                              np.power(df['%sY' % station], 2))\n",
    "        else:\n",
    "            dfTemp['%sH' % station] = df['%sH' % station]\n",
    "        dfTemp['%sV' % station] = df['%sZ' % station]\n",
    "        return dfTemp\n",
    "\n",
    "\n",
    "def MakeDF(years, dirpath, returnDF=False):\n",
    "    station = dirpath.split('/')[-1]\n",
    "    startYr, endYr = years\n",
    "    df = None\n",
    "    for year in range(startYr, endYr):\n",
    "        print(\"parsing %d\" % (year))\n",
    "        fileGen = glob.iglob(os.path.join(dirpath, '%d/*' % year))\n",
    "        dataList = [ParseTxtFile(file, station=station.upper()) for file in fileGen]\n",
    "        dfTemp = pd.concat(dataList)\n",
    "        if df is None:\n",
    "            df = dfTemp\n",
    "        else:\n",
    "            df = pd.concat((df, dfTemp))\n",
    "    df.to_pickle(os.path.join(pkldir, 'dfMag_Comp_%s.pkl' % station))\n",
    "    if returnDF:\n",
    "        return df\n",
    "    else:\n",
    "        del df\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing 1999\n",
      "parsing 2000\n",
      "parsing 2001\n",
      "parsing 2002\n",
      "parsing 2003\n",
      "parsing 2004\n",
      "parsing 2005\n",
      "parsing 2006\n",
      "parsing 2007\n",
      "parsing 2008\n",
      "parsing 2009\n",
      "parsing 2010\n",
      "parsing 2011\n",
      "parsing 2012\n",
      "parsing 2013\n",
      "parsing 2014\n"
     ]
    }
   ],
   "source": [
    "dp = dataFRD\n",
    "years=(1999, 2015)\n",
    "MakeDF(years, dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfFRD = pd.read_pickle(os.path.join(pkldir, 'dfMag_Comp_%s.pkl' %(dataFRD.split('/')[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing 1999\n",
      "parsing 2000\n",
      "parsing 2001\n",
      "parsing 2002\n",
      "parsing 2003\n",
      "parsing 2004\n",
      "parsing 2005\n",
      "parsing 2006\n",
      "parsing 2007\n",
      "parsing 2008\n",
      "parsing 2009\n",
      "parsing 2010\n",
      "parsing 2011\n",
      "parsing 2012\n",
      "parsing 2013\n"
     ]
    }
   ],
   "source": [
    "dp = dataOTT\n",
    "years=(1999, 2014)\n",
    "MakeDF(years, dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfOTT = pd.read_pickle(os.path.join(pkldir, 'dfMag_Comp_%s.pkl' %(dataOTT.split('/')[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFRD = pd.read_pickle(os.path.join(pkldir, 'dfMag_Comp_%s.pkl' %(dataFRD.split('/')[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMag = pd.merge(dfFRD,dfOTT, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfMag.to_pickle('../PklJar/dfMAG.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
